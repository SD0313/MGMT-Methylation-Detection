{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'alloc': 0, 'total': 11178, 'percentage': 0.0},\n",
       " 1: {'alloc': 0, 'total': 11178, 'percentage': 0.0},\n",
       " 2: {'alloc': 10913, 'total': 11178, 'percentage': 0.9762927178386116},\n",
       " 3: {'alloc': 0, 'total': 11178, 'percentage': 0.0}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jarvis.utils.general import gpus\n",
    "gpus.find_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'alloc': 0, 'total': 11178, 'percentage': 0.0},\n",
       " 1: {'alloc': 0, 'total': 11178, 'percentage': 0.0},\n",
       " 3: {'alloc': 0, 'total': 11178, 'percentage': 0.0}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus.find_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2022-07-02 15:11:09 ] CUDA_VISIBLE_DEVICES automatically set to: 0           \n"
     ]
    }
   ],
   "source": [
    "gpus.autoselect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from jarvis.train import datasets\n",
    "from jarvis.utils.display import imshow\n",
    "from tensorflow.keras import Input\n",
    "from jarvis.train.client import Client\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mri(mri):\n",
    "    for i in range(mri.shape[0]):\n",
    "        clear_output(wait=True)\n",
    "        plt.axis(False)\n",
    "        plt.imshow(mri[i, :, :, 0], cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- prepare generators\n",
    "client = Client('/data/raw/miccai_rsna/data/ymls/client-3d.yml')\n",
    "gen_train, gen_valid = client.create_generators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Show a sample training set\n",
    "xs, ys = next(gen_train)\n",
    "# imshow(xs['t2w'][0][24], radius=1)\n",
    "ys['lbl'].reshape(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 48, 96, 96, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flair = xs['fla']\n",
    "flair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair1 = flair[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 96, 96, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flair1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9031360994148053"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(flair1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAADjUlEQVR4nO3YMU4sORRAUdfoL4WAjIicxbEgchZCQggCiaDVqFtQajX+G4DJRnU1nBPayUuu/ORlzjmAnn+2HgD4njghSpwQJU6IEidE/fm3y2VZfOXCf2zOuXx37uWEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlRf7YegO1dXFyMq6ursa7reHl5GcfjcTw9PY3D4bD1aL+aOBk3Nzfj9vZ2vL29jfv7+/H8/Dzu7u7EuTFrLWNd17Hb7cb7+/v4+PgYn5+f43w+bz3Wr7fMOX++XJafL/nfuLy8HNfX12Nd1/H6+jqOx+N4fHwc+/1+69F+hTnn8t25tZax2+3Gw8PDmHOOw+Ew1nUdp9Np67F+PXEy9vv9OJ/PY845TqfT+Pr6Guu6bj3Wr2ethY39tNb6EIIocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtQy59x6BuAbXk6IEidEiROixAlR4oQocULUXy8pepjSGOakAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_mri(flair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lbl': array([[[[[0]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[1]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[0]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[0]]]]], dtype=uint8)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys['lbl'][:, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['t2w', 't1w', 't1wce', 'fla', 'lbl'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xs key: t2w      | shape = (4, 48, 96, 96, 1)\n",
      "xs key: t1w      | shape = (4, 48, 96, 96, 1)\n",
      "xs key: t1wce    | shape = (4, 48, 96, 96, 1)\n",
      "xs key: fla      | shape = (4, 48, 96, 96, 1)\n",
      "xs key: lbl      | shape = (4, 1, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# --- Print keys \n",
    "for key, arr in xs.items():\n",
    "    print('xs key: {} | shape = {}'.format(key.ljust(8), arr.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create model inputs\n",
    "inputs = client.get_inputs(Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t2w': <KerasTensor: shape=(None, 48, 96, 96, 1) dtype=float32 (created by layer 't2w')>,\n",
       " 't1w': <KerasTensor: shape=(None, 48, 96, 96, 1) dtype=float32 (created by layer 't1w')>,\n",
       " 't1wce': <KerasTensor: shape=(None, 48, 96, 96, 1) dtype=float32 (created by layer 't1wce')>,\n",
       " 'fla': <KerasTensor: shape=(None, 48, 96, 96, 1) dtype=float32 (created by layer 'fla')>,\n",
       " 'lbl': <KerasTensor: shape=(None, 1, 1, 1, 1) dtype=uint8 (created by layer 'lbl')>}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ResNet10.ResNet10_3D import build_resnet\n",
    "base_model = build_resnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2), loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "bce = BinaryCrossentropy()\n",
    "# @tf.function\n",
    "def train_step(x, y):\n",
    "#     print(y.shape)\n",
    "    loss = base_model.train_on_batch(x, y)\n",
    "#     with tf.GradientTape() as tape:\n",
    "# #         print('beginning training...')\n",
    "#         y_hat = base_model(x, training=True)\n",
    "# #         print(y_hat.shape)\n",
    "# #         print('done training...')\n",
    "#         loss = bce(y, y_hat)\n",
    "#     grads = tape.gradient(loss, base_model.trainable_variables)\n",
    "#     opt.apply_gradients(zip(grads, base_model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "annoying_case = None\n",
    "annoying_case_unproc = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataset, n_epochs=1, max_steps_per_epoch=None):\n",
    "    global annoying_case, annoying_case_unproc\n",
    "    for epoch in range(n_epochs):\n",
    "        for i, batch in enumerate(train_dataset):\n",
    "            xs, ys = batch\n",
    "            inp = np.empty((4, 48, 96, 96, 4))\n",
    "            inp[:, :, :, :, 0] = xs['t2w'][:, :, :, 0]\n",
    "            inp[:, :, :, :, 1] = xs['t1w'][:, :, :, 0]\n",
    "            inp[:, :, :, :, 2] = xs['t1wce'][:, :, :, 0]\n",
    "            inp[:, :, :, :, 3] = xs['fla'][:, :, :, 0]\n",
    "            inp = tf.image.per_image_standardization(inp)\n",
    "#             print(xs['fla'].shape)\n",
    "#             fla = xs['fla']\n",
    "            x_prep = inp # (inp-np.min(inp))/(np.max(inp)-np.min(inp))\n",
    "            if max_steps_per_epoch is not None:\n",
    "                if i == max_steps_per_epoch:\n",
    "                    break\n",
    "#             adversarial = (epoch >= 1)\n",
    "            if(np.isnan(x_prep).any()):\n",
    "                continue\n",
    "            l1 = base_model.train_on_batch(x_prep, ys['lbl'].reshape(4, 1))\n",
    "#             train_step(x_prep, ys['lbl'].reshape(4, 1))#[:, 0, 0, 0])\n",
    "#             del batch\n",
    "            clear_output(wait=True)\n",
    "            if np.isnan(np.max(x_prep)) or np.isnan(np.min(x_prep)):\n",
    "                annoying_case = x_prep\n",
    "                annoying_case_unproc = fla\n",
    "#             show_mri(x_prep[0])\n",
    "            print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))\n",
    "            print(f'Step {i+1}')\n",
    "#             print(f'MRI Shape: {x_prep.shape}')\n",
    "#             print(f'Max Flair: {np.max(x_prep)}')\n",
    "#             print(f'Min Flair: {np.min(x_prep)}')\n",
    "            print(f'Loss: {l1}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "Step 100\n",
      "Loss: [1.8463215827941895, 0.25]\n"
     ]
    }
   ],
   "source": [
    "# --- prepare generators\n",
    "client = Client('/data/raw/miccai_rsna/data/ymls/client-3d.yml')\n",
    "gen_train, gen_valid = client.create_generators()\n",
    "train(gen_train, max_steps_per_epoch=100, n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_VAL_SCANS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caidm/jarvis/jarvis-core/jarvis/train/client/client.py:983: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arr_ = arr / scale\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "for i, batch in enumerate(gen_train):\n",
    "    xs, ys = batch\n",
    "    inp = np.empty((4, 48, 96, 96, 4))\n",
    "    inp[:, :, :, :, 0] = xs['t2w'][:, :, :, 0]\n",
    "    inp[:, :, :, :, 1] = xs['t1w'][:, :, :, 0]\n",
    "    inp[:, :, :, :, 2] = xs['t1wce'][:, :, :, 0]\n",
    "    inp[:, :, :, :, 3] = xs['fla'][:, :, :, 0]\n",
    "    inp = tf.image.per_image_standardization(inp)\n",
    "    pred = base_model.predict(inp)\n",
    "    y = ys['lbl']\n",
    "    labels.append(y.reshape(4, 1))\n",
    "    preds.append(pred)\n",
    "    if i == NUM_VAL_SCANS:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array(preds).reshape(-1,)\n",
    "labels = np.array(labels).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 0.99984443, 0.99692   , 1.        ,\n",
       "       0.99999964, 0.9999058 , 1.        , 0.9999478 , 0.9988187 ,\n",
       "       0.9999738 , 0.9998178 , 1.        , 0.992762  , 1.        ,\n",
       "       0.9995172 , 0.99947137, 0.999708  , 0.9988784 , 0.99866915,\n",
       "       0.9997018 , 1.        , 0.99537957, 0.99925643, 0.9907374 ,\n",
       "       0.9983254 , 0.9959447 , 1.        , 0.99891305, 1.        ,\n",
       "       0.9997291 , 0.99996686, 1.        , 0.9999851 , 1.        ,\n",
       "       0.99998605, 0.9993672 , 0.99997056, 1.        , 0.9999448 ,\n",
       "       0.9983146 , 0.9940796 , 0.9998148 , 0.9995764 , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.9926702 , 0.999997  ,\n",
       "       1.        , 1.        , 0.99806625, 0.99150616, 1.        ,\n",
       "       0.9928369 , 1.        , 0.99765956, 1.        , 1.        ,\n",
       "       0.99942076, 0.99999976, 0.9999906 , 0.99964726, 0.999673  ,\n",
       "       0.99977416, 0.983489  , 0.9999875 , 0.999073  , 1.        ,\n",
       "       1.        , 0.99994147, 0.9997733 , 0.9996145 , 0.9991303 ,\n",
       "       0.9998367 , 1.        , 0.99994063, 1.        , 1.        ,\n",
       "       0.99996674, 0.9999876 , 0.99934834, 1.        , 0.9999975 ,\n",
       "       1.        , 1.        , 0.99978846, 1.        , 0.99999046,\n",
       "       0.9999788 , 1.        , 1.        , 0.9999672 , 0.99850214,\n",
       "       0.99997675, 0.99987257, 0.99963593, 0.9999926 , 1.        ,\n",
       "       0.9999628 , 1.        , 0.9998913 , 1.        , 1.        ,\n",
       "       0.99948967, 0.99998915, 0.99400747, 1.        , 0.99999905,\n",
       "       0.99999845, 0.9999999 , 1.        , 1.        , 0.99999917,\n",
       "       1.        , 1.        , 0.99933076, 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.99930835, 1.        ,\n",
       "       0.999476  , 0.9999981 , 0.998823  , 0.9997271 , 0.99999833,\n",
       "       0.9999994 , 0.9915696 , 1.        , 1.        , 0.9999478 ,\n",
       "       1.        , 1.        , 0.99997044, 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.9999709 , 0.99783725,\n",
       "       1.        , 1.        , 1.        , 1.        , 0.9959194 ,\n",
       "       0.999998  , 0.9991999 , 0.99997544, 0.99991703, 1.        ,\n",
       "       1.        , 0.99926263, 1.        , 0.997336  , 0.9999993 ,\n",
       "       1.        , 0.9999995 , 0.9947743 , 0.9995043 , 1.        ,\n",
       "       0.9996493 , 0.99367297, 0.9997218 , 1.        , 0.99951434,\n",
       "       1.        , 0.99999976, 0.9995548 , 0.9999945 , 1.        ,\n",
       "       0.99961334, 1.        , 1.        , 0.99725217, 0.9959416 ,\n",
       "       0.9999995 , 1.        , 1.        , 1.        , 0.9991043 ,\n",
       "       0.9944143 , 0.9998963 , 0.99994135, 0.999972  , 0.9987783 ,\n",
       "       1.        , 0.99981636, 1.        , 1.        , 0.99999833,\n",
       "       0.9997687 , 1.        , 0.9957516 , 1.        , 0.9999703 ,\n",
       "       0.99998665, 1.        , 1.        , 0.9998412 , 1.        ,\n",
       "       0.99997604, 1.        , 1.        , 0.9997584 , 0.99952734,\n",
       "       1.        , 0.9946374 , 0.9999964 , 0.9991596 , 0.99838257,\n",
       "       1.        , 0.9999727 , 0.9993216 , 0.9999143 , 1.        ,\n",
       "       0.9911561 , 0.9980489 , 0.9996345 , 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.9904152 , 1.        , 1.        ,\n",
       "       0.9991211 , 0.99986196, 0.9999989 , 0.998946  , 0.9970143 ,\n",
       "       0.99985313, 0.99996996, 0.99995124, 0.99882215, 1.        ,\n",
       "       0.999998  , 1.        , 0.999482  , 1.        , 1.        ,\n",
       "       0.9880652 , 0.9991339 , 1.        , 0.9999999 , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.9999156 , 1.        ,\n",
       "       0.99930954, 1.        , 1.        , 0.9855724 , 0.9963336 ,\n",
       "       0.9997595 , 1.        , 1.        , 0.9994437 , 0.99997354,\n",
       "       1.        , 1.        , 0.99999595, 1.        , 1.        ,\n",
       "       0.9997918 , 0.9994005 , 1.        , 1.        , 0.9988432 ,\n",
       "       0.9998354 , 1.        , 0.99921846, 0.99999106, 0.9999951 ,\n",
       "       1.        , 0.99998784, 1.        , 1.        , 0.9992143 ,\n",
       "       0.9997174 , 1.        , 0.9999466 , 0.99890804, 0.9997696 ,\n",
       "       1.        , 1.        , 1.        , 1.        , 0.99685353,\n",
       "       1.        , 0.99923396, 1.        , 0.9997248 , 0.99963415,\n",
       "       0.9997954 , 0.99275887, 0.999979  , 0.9925719 , 0.9910383 ,\n",
       "       1.        , 1.        , 0.9999826 , 0.99731785, 1.        ,\n",
       "       1.        , 1.        , 0.9999664 , 0.99426854, 1.        ,\n",
       "       1.        , 0.9954562 , 0.9999814 , 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.9996761 , 0.9998324 , 0.9997559 ,\n",
       "       1.        , 1.        , 1.        , 0.9999999 , 0.9999888 ,\n",
       "       1.        , 1.        , 1.        , 0.9999714 , 0.9999708 ,\n",
       "       0.9998148 , 0.98892444, 0.99996305, 0.997934  , 0.99903893,\n",
       "       0.9977124 , 1.        , 0.99967706, 0.9998109 , 0.9998301 ,\n",
       "       0.9995639 , 1.        , 0.9999032 , 0.99998355, 0.999049  ,\n",
       "       0.99869555, 0.9999887 , 0.99975914, 1.        , 1.        ,\n",
       "       0.9999999 , 0.99999404, 0.99975616, 1.        , 0.9999999 ,\n",
       "       0.9996209 , 0.9992963 , 0.99932456, 1.        , 0.9998585 ,\n",
       "       0.9963994 , 1.        , 0.9986253 , 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.99880147, 0.99875414, 1.        ,\n",
       "       0.99608237, 0.9999733 , 1.        , 0.98978394, 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.9976368 , 0.9999999 ,\n",
       "       0.9981183 , 1.        , 1.        , 0.99985516, 1.        ,\n",
       "       1.        , 0.99961925, 0.9993863 , 0.99848   , 0.996917  ,\n",
       "       0.99992704, 0.99998724, 0.99998486, 0.99986887, 0.9987747 ,\n",
       "       0.9999685 , 0.9952904 , 1.        , 0.9999517 , 1.        ,\n",
       "       0.9989839 , 1.        , 0.9998288 , 0.99994195, 0.99989116,\n",
       "       1.        , 0.99998844, 0.9982681 , 0.998744  , 0.99991775,\n",
       "       0.9996458 , 0.99981683, 0.99994755, 0.99913764, 1.        ,\n",
       "       1.        , 0.99999046, 0.99995947, 0.9999131 , 0.99953175,\n",
       "       1.        , 1.        , 0.9990421 , 0.9906922 , 1.        ,\n",
       "       1.        , 1.        , 0.9955187 , 0.9999199 , 0.9987367 ,\n",
       "       0.99707913, 1.        , 0.99812883, 0.99981385, 0.9999988 ,\n",
       "       0.99999905, 0.99989915, 0.9988311 , 0.999998  , 0.9909219 ,\n",
       "       1.        , 0.9999387 , 0.9998853 , 0.9996611 , 1.        ,\n",
       "       0.9999932 , 0.9999856 , 1.        , 0.9992717 , 0.9999771 ,\n",
       "       0.99877197, 1.        , 0.9999771 , 0.9760439 , 1.        ,\n",
       "       0.9993594 , 0.9996712 , 0.999652  , 0.9772529 , 1.        ,\n",
       "       0.9999962 , 0.9981294 , 0.9997718 , 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.99969316, 0.99910337, 0.9675427 ,\n",
       "       1.        , 1.        , 0.99829715, 1.        , 1.        ,\n",
       "       1.        , 0.99806124, 0.99739337, 0.99996793, 1.        ,\n",
       "       0.99999964, 1.        , 0.99425584, 0.99670047, 1.        ,\n",
       "       0.99833244, 1.        , 0.9990803 , 0.99937326, 0.9999994 ,\n",
       "       1.        , 0.9926602 , 1.        , 0.99608624, 0.99996257,\n",
       "       0.9999244 , 1.        , 1.        , 0.9999145 , 0.998028  ,\n",
       "       0.9986332 , 1.        , 0.9996964 , 0.9999976 , 1.        ,\n",
       "       0.9999465 , 1.        , 0.9999976 , 0.99996114, 0.9991709 ,\n",
       "       1.        , 0.9999914 , 1.        , 1.        , 1.        ,\n",
       "       1.        , 0.99817646, 0.9999993 , 0.99921906, 0.9978886 ,\n",
       "       0.99974436, 0.9990326 , 1.        , 0.9996057 , 1.        ,\n",
       "       1.        , 0.99982196, 0.9999707 , 0.99998736, 0.99990964,\n",
       "       0.98838323, 1.        , 0.9996171 , 0.99934417, 0.998464  ,\n",
       "       1.        , 0.99999833, 0.99988365, 0.99976605, 0.9946102 ,\n",
       "       0.9946243 , 1.        , 1.        , 0.99997914, 0.9999206 ,\n",
       "       1.        , 0.9995394 , 0.99464226, 0.9999616 , 0.9999989 ,\n",
       "       0.9989722 , 0.99969065, 1.        , 1.        , 1.        ,\n",
       "       1.        , 0.99868494, 1.        , 1.        , 0.99948764,\n",
       "       0.9999045 , 0.9982692 , 0.99962044, 0.9997483 , 1.        ,\n",
       "       0.9999881 , 0.99943584, 0.99987745, 1.        , 1.        ,\n",
       "       0.9997981 , 0.99838567, 0.99999547, 0.9875707 , 0.99990296,\n",
       "       0.9990513 , 1.        , 1.        , 0.9999988 , 1.        ,\n",
       "       0.9999994 , 0.99961936, 1.        , 0.9997967 , 0.9999093 ,\n",
       "       0.9999958 , 0.9997068 , 0.9989448 , 0.9999784 , 1.        ,\n",
       "       1.        , 0.9999964 , 1.        , 1.        , 0.9940673 ,\n",
       "       1.        , 0.99818015, 0.9999771 , 0.99973506, 0.99997735,\n",
       "       1.        , 1.        , 0.99903774, 0.9998696 , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.99994135, 1.        ,\n",
       "       1.        , 0.9999505 , 0.9996693 , 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.9984559 , 0.9997271 , 0.9998561 ,\n",
       "       0.9924185 , 1.        , 0.9999622 , 1.        , 0.97311234,\n",
       "       0.992753  , 1.        , 1.        , 1.        , 0.9999695 ,\n",
       "       1.        , 0.99947196, 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.99976295, 0.99864906,\n",
       "       0.9999769 , 0.9999664 , 0.9981006 , 1.        , 1.        ,\n",
       "       0.99295545, 0.9999982 , 1.        , 1.        , 1.        ,\n",
       "       0.99999976, 0.9999614 , 1.        , 0.99491775, 0.999708  ,\n",
       "       1.        , 0.9984806 , 0.99994266, 1.        , 0.9992391 ,\n",
       "       0.9999825 , 0.9966317 , 0.9994242 , 0.9999976 , 0.99922717,\n",
       "       0.99276453, 1.        , 0.99998343, 1.        , 0.99995387,\n",
       "       0.9988217 , 0.9999337 , 0.99832636, 0.99942905, 0.99984944,\n",
       "       1.        , 1.        , 1.        , 0.9995065 , 0.9999851 ,\n",
       "       0.99756855, 1.        , 0.99740136, 0.9816103 , 1.        ,\n",
       "       0.99984634, 0.9999633 , 0.99962234, 0.98902893, 0.99954116,\n",
       "       0.9994758 , 1.        , 1.        , 0.99981576, 1.        ,\n",
       "       0.9996823 , 1.        , 1.        , 0.99995124, 1.        ,\n",
       "       0.9999708 , 0.9999398 , 0.99999976, 0.9999999 , 0.9996494 ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 0.99991965,\n",
       "       1.        , 1.        , 0.99596965, 1.        , 1.        ,\n",
       "       1.        , 0.99856466, 0.97983176, 1.        , 0.9900457 ,\n",
       "       1.        , 0.9996137 , 1.        , 1.        , 0.99975926,\n",
       "       1.        , 0.9999609 , 1.        , 0.9999819 , 1.        ,\n",
       "       0.99491465, 1.        , 0.9999049 , 1.        , 0.99999094,\n",
       "       0.99921155, 1.        , 0.9981201 , 1.        , 0.9990976 ,\n",
       "       0.99901116, 1.        , 0.9999994 , 0.9975485 , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 0.99405813,\n",
       "       0.99968743, 0.99991524, 1.        , 0.99800164, 0.99984336,\n",
       "       0.99991643, 0.99901056, 0.9957681 , 0.9999912 , 1.        ,\n",
       "       0.99852633, 0.9999651 , 0.99993086, 1.        , 0.99947935,\n",
       "       0.99869955, 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.99524045, 0.99732935, 1.        , 0.97878563, 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.9960491 , 0.999871  ,\n",
       "       0.9956937 , 0.9998636 , 0.99477464, 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.9983784 , 0.9999989 , 0.9999708 , 0.9999013 ], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_preds = np.zeros(preds.shape)\n",
    "disc_preds[preds > 0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated on 200 scans...\n",
      "Accuracy: 0.48756218905472637\n",
      "AUC: 0.4542426193778482\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(labels, disc_preds)\n",
    "auc = roc_auc_score(labels, preds)\n",
    "print(f'Validated on {NUM_VAL_SCANS} scans...')\n",
    "print(f'Accuracy: {acc}')\n",
    "print(f'AUC: {auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
