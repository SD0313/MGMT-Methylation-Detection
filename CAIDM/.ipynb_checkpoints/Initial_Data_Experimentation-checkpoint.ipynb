{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun 12 14:50:33 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 23%   26C    P8    16W / 250W |  10916MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:5E:00.0 Off |                  N/A |\n",
      "| 23%   24C    P8     8W / 250W |  10680MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:AF:00.0 Off |                  N/A |\n",
      "| 23%   22C    P8     8W / 250W |  10814MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:D8:00.0 Off |                  N/A |\n",
      "| 23%   24C    P8     8W / 250W |  10680MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[ 2022-06-12 14:50:34 ] CUDA_VISIBLE_DEVICES already manually set to: -1       \n"
     ]
    }
   ],
   "source": [
    "from jarvis.utils.general import gpus\n",
    "\n",
    "gpus.autoselect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from jarvis.train import datasets\n",
    "from jarvis.utils.display import imshow\n",
    "from tensorflow.keras import Input\n",
    "from jarvis.train.client import Client\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mri(mri):\n",
    "    for i in range(mri.shape[0]):\n",
    "        clear_output(wait=True)\n",
    "        plt.axis(False)\n",
    "        plt.imshow(mri[i, :, :, 0], cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- prepare generators\n",
    "client = Client('/data/raw/miccai_rsna/data/ymls/client-3d.yml')\n",
    "gen_train, gen_valid = client.create_generators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1]]]]\n"
     ]
    }
   ],
   "source": [
    "# --- Show a sample training set\n",
    "xs, ys = next(gen_train)\n",
    "# imshow(xs['t2w'][0][24], radius=1)\n",
    "print(ys['lbl'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 48, 96, 96, 1)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flair = xs['fla']\n",
    "flair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair1 = flair[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 96, 96, 1)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flair1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAALP0lEQVR4nO3dyW4bxxqG4a/ngaRiKUJiZ+FNbiF3nbVvwUEuwAGCDA4y29ZEk2oOPZ2FUXVajGzgHJPiH/J9AEGzQS9eVXd1dXXQ970A2BPu+wUAuB9xAkYRJ2AUcQJGESdgVPyhbwZBwFQusGN93wf3fZ2REzCKOAGjiBMwijgBo4gTMIo4AaOIEzCKOAGjiBMwijgBo4gTMIo4AaOIEzCKOAGjiBMwijgBo4gTMIo4AaOIEzCKOAGjiBMwijgBo4gTMIo4AaOIEzCKOAGjiBMwijgBo4gTMIo4AaOIEzCKOAGjiBMwijgBo4gTMIo4AaOIEzCKOAGjiBMwijgBo4gTMIo4AaOIEzCKOAGjiBMwijgBo4gTMIo4AaOIEzCKOAGjiBMwijgBo4gTMIo4AaOIEzCKOAGjiBMwijgBo4gTMIo4AaOIEzCKOAGjiBMwijgBo4gTMIo4AaOIEzCKOAGjiBMwijgBo4gTMIo4AaOIEzCKOAGjiBMwijgBo4gTMIo4AaPifb8ASEEQKIqiO1+LokhRFCkMQ0VRpL7v1XWd+r5XXddq29Z/jsNEnAaEYag4jhUEgY8tTVMlSeLf+r5X0zRq21ZVVfnfbdt2Xy8bO0acBrhR0UUahqGKolCapiqKQpPJxP9c27a6uLjQYrHQcrnUarXyv4/DQpwGuOgkKc9zpWmqsixVlqXOzs705MkTRVGkOI7VNI1++OEHXV9fazqd+t+t65pD3ANDnHsUBIGCIPAjZhzHfsQsy9KPnKPRyJ9/Nk2jsiy1Wq3Utq36vr/zMSPo4Qg+9Nc2CAL+FO9QHMdK01RpmmoymSjLMp2fn6soCiVJoiiK9Nlnn+np06eSpK7rVNe1Xr16pfl8rqqqtFwudXl5qZcvX6qua3+Yi3+Pvu+D+77OyLknboY2jmMlSaIsy5TnuYqi8Ie2YRj6j6V3kz9hGKosS0n/jXuxWChNU/V9r/V6TZwHgjgfUBiGCsNQaZoqjmMfZJqmGo/HStNUWZYpyzJNJhMVRaGiKNQ0jaIoUlEUftZ2NBppNpupqiq1bavlcqmqqvTrr79quVzu+7+KLSDOBzSMM01T5Xnu48yyTEmSKI5jRVGkPM81Go2UJIkfMZMkURiGfgLIXescj8c6Pz/Xzc3NP66X4t+LOB+Am/RxkzrDNxfpo0ePlCSJxuOxkiTxs7VuUijLMp2dnSmOYy0WC63Xay0WC83nc83nc93c3Gg+n3Pd84AQ5465MIdxuvfunHE0Guns7Myfe8ZxrLIsNRqN/AhalqW++OILxXGs5XKp9XqtP//8U1VV6e3bt7q4uPCztjgMxLlD7lKJC9TNwLrVP250zPPcH866CSL3M1mWqSgKjcdjnZ6eKo5jXV9fq+s6tW2rxWLhZ21XqxWXUg4Ice6IGy1dnG5CJ0kSTSYT5XmuTz75ROfn54rj2Ac6Ho8Vx7EfLU9OTvTpp5/q0aNH+vLLL++cc65WK11dXenq6kqXl5f+HBSHgTh3bLjAwI2GbomemxhyX3PXO/M818nJyZ1D2yzL/Gqg6XSqN2/eaDqdqqoqfzhLmIeFOHfErdbJ81xnZ2f+cok7fA2C4M5kz8nJiSaTib766is/mm7elfLHH39oOp3q66+/1osXL/T777/r77//Vl3XhHmAiHPH3GURNyvrLnX0fe/Dc9c8y7LU+fm5Hj9+7A+H27b11zFvbm50cXGhn3/+Wd9//71ms5nm8/me/4fYFeLcEXcNM89zheG7e9qbppH07nYwF2XXdcqyTE+ePNHJyYnCMNRqtfIj5+vXr/XLL7/o1atX+uabb3R5eanvvvtO0+lUdV3v87+IHSPOHXGzsUmS+K91XaemafyhbBiG6vteURTp9PRUk8lEQRCorms/oTSdTvXjjz/qp59+0rNnz3R1dcUh7JEgzi1zUblJIPc2XHjguMPZMAw1m83Utq0//HUBvnjxQt9++61ev36t5XLJutkjQpxb5g5H3Q4Gwwmg++Isy1JhGOr6+lrz+Vx1XStNU83ncy0WCz1//lzPnj3Ter1mgcGRIc4tCoLAv3cL1B03EeT2Bur7XlVVaT6f+ztJ3M3UURTp6upKs9lMb9688etocVyIc0uGq4Ekab1e3/mem7UNw1C3t7cKw1BVVWk6nfrzUzeydl2nly9f6q+//tLt7e2dyHE8iHMH3DVOF1UQBOq6zo+abr+gqqr8+WnTNHdG3IuLC7/qB8eJnRC2xJ1XDtfSuuV77uMkSe4c+rp1tI67WbptW93e3voJICaBDtv7dkIgzi1wh63DrS2HoQ5X+gx/xkU73PZyuVwyWh4ZtinZITe6bf6h6/veBzr8ftd16rruzvfcBtFcw4RDnFvyoSOQtm39eackP0oCH0KcW/K+UXM4er7vZ4H7EOeW3BccEeJj8JQxwCjiBIwiTsAo4gSMIk7AKGZrt2C4Gshdy2SmFh+LOLdg87HxLkwCxccgzo/kFhf8vyG6m6+Hy/gAiTg/irvjRJKPanM1kPT+cN3tYsN/x92Vct+aXBwX4vxI9y3b+9Dn9/3+5ui7eeM2cR4nbhnbo2GAm0E6w/NXFssfJm4ZM8gdsg6DdDv1uVvI3nc7Gg4fcRrgHmCUZZkeP36sPM/9Bl9VVWk2mxHnESJOA6Io8g8tevr0qSaTid8Nvm1bvX37ljiPEHHukdtDKM9zFUWhNE21WCz898fjsZqmUZqmatuWXfiODHHukXuqdVEUGo1GSpJEt7e3WiwWiuNYp6en/vENbu9aRtDjQZx7sLnhV9d1Pj63qbSLsKoqtjU5UlxK2YOyLP2TxjZDld7N4rqtMd0jAJmxPVxcSjFgeC1zGKK7bOI+7/teq9VKy+Vyny8Xe0acO+Y2j3ZL9Nx7tz2mM3zAEWtsIRHnzg2jdJFK/9zr9n9d9ofDR5wPoOs6xXGs0WikOI61Xq/VNI2f6NlcsicRJ4hzp4ajZBAE/lqmJL/j++ZED3eiwCHOHXGHs2maqizLO2tmkyRRFEVar9eKokht22q1Wt3ZiJpzThDnjrjLI2VZ6vPPP1cQBD7AsiyVJImfkV0sFrq9veVaJu4gzh2570bspmnU972SJFHbtn5k7bpOZVmqaRqtVitGTUhiEcLOpGmqJEn82llJqutakvy5p1u217at6rrWarXSb7/9pqqq9vnS8cBYhPCAhg/Q7fveR+kOW90yPXeOGcex3yBseL0Tx404t2x4TTNJEnVdp/V6fed7LtKqqvyllCiKVNc1h7TwiHPLho+Zd7OzTdPcu7fter32o2eapv5zQCLOrXPrZNfrtV+iN5yFdXGGYaimaVTXtYIg8IvcuWcTDhNCO3Lfhl3ufNLdgTI8Lx0ueOfQ9rgwIfTA7vuj51YFufebG3kN704BiHOHNnfX23wU/XAJ3zBSQCLOBzHcLPp9j6cnTGwizge0eXvY8HyUMLGJOPeIIPEhLEcBjCJOwCjiBIwiTsAo4gSMIk7AKOIEjCJOwCjiBIwiTsAo4gSMIk7AKOIEjCJOwCjiBIwiTsAo4gSMIk7AKOIEjCJOwCjiBIwiTsAo4gSMIk7AKOIEjCJOwCjiBIwiTsAo4gSMIk7AKOIEjCJOwCjiBIwiTsAo4gSMIk7AKOIEjCJOwCjiBIwiTsAo4gSMIk7AKOIEjCJOwCjiBIwiTsAo4gSMIk7AKOIEjCJOwCjiBIwiTsAo4gSMIk7AKOIEjCJOwCjiBIwiTsAo4gSMIk7AKOIEjCJOwCjiBIwiTsAo4gSMIk7AKOIEjCJOwCjiBIwiTsAo4gSMIk7AKOIEjAr6vt/3awBwD0ZOwCjiBIwiTsAo4gSMIk7AKOIEjPoPkGM5Y1UpWuQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_mri(flair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lbl': array([[[[[1]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[1]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[0]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[0]]]]], dtype=uint8)}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]], dtype=uint8)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys['lbl'][:, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['t2w', 't1w', 't1wce', 'fla', 'lbl'])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xs key: t2w      | shape = (4, 48, 96, 96, 1)\n",
      "xs key: t1w      | shape = (4, 48, 96, 96, 1)\n",
      "xs key: t1wce    | shape = (4, 48, 96, 96, 1)\n",
      "xs key: fla      | shape = (4, 48, 96, 96, 1)\n",
      "xs key: lbl      | shape = (4, 1, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# --- Print keys \n",
    "for key, arr in xs.items():\n",
    "    print('xs key: {} | shape = {}'.format(key.ljust(8), arr.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create model inputs\n",
    "inputs = client.get_inputs(Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t2w': <KerasTensor: shape=(None, 48, 96, 96, 1) dtype=float32 (created by layer 't2w')>,\n",
       " 't1w': <KerasTensor: shape=(None, 48, 96, 96, 1) dtype=float32 (created by layer 't1w')>,\n",
       " 't1wce': <KerasTensor: shape=(None, 48, 96, 96, 1) dtype=float32 (created by layer 't1wce')>,\n",
       " 'fla': <KerasTensor: shape=(None, 48, 96, 96, 1) dtype=float32 (created by layer 'fla')>,\n",
       " 'lbl': <KerasTensor: shape=(None, 1, 1, 1, 1) dtype=uint8 (created by layer 'lbl')>}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv3D, GlobalAveragePooling3D, Flatten, Input, MaxPool3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.Sequential()\n",
    "base_model.add(Input(shape=(48, 96, 96, 1)))\n",
    "base_model.add(Conv3D(16, 3, activation='relu', padding='same'))\n",
    "base_model.add(MaxPool3D(padding='same'))\n",
    "base_model.add(Conv3D(32, 3, activation='relu', padding='same'))\n",
    "base_model.add(MaxPool3D(padding='same'))\n",
    "base_model.add(Conv3D(48, 3, activation='relu', padding='same'))\n",
    "base_model.add(MaxPool3D(padding='same'))\n",
    "base_model.add(Conv3D(64, 3, activation='relu', padding='same'))\n",
    "base_model.add(MaxPool3D(padding='same'))\n",
    "base_model.add(Conv3D(80, 3, activation='relu', padding='same'))\n",
    "base_model.add(MaxPool3D(padding='same'))\n",
    "\n",
    "base_model.add(GlobalAveragePooling3D())\n",
    "base_model.add(Dense(128, activation='relu'))\n",
    "base_model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_87 (Conv3D)           (None, 48, 96, 96, 16)    448       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_75 (MaxPooling (None, 24, 48, 48, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_88 (Conv3D)           (None, 24, 48, 48, 32)    13856     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_76 (MaxPooling (None, 12, 24, 24, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_89 (Conv3D)           (None, 12, 24, 24, 48)    41520     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_77 (MaxPooling (None, 6, 12, 12, 48)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_90 (Conv3D)           (None, 6, 12, 12, 64)     83008     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_78 (MaxPooling (None, 3, 6, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_91 (Conv3D)           (None, 3, 6, 6, 80)       138320    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_79 (MaxPooling (None, 2, 3, 3, 80)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling3d_2 ( (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               10368     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 287,649\n",
      "Trainable params: 287,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam()\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_hat = base_model(x, training=True)\n",
    "        bce = BinaryCrossentropy()\n",
    "        loss = bce(y, y_hat)\n",
    "    grads = tape.gradient(loss, base_model.trainable_variables)\n",
    "    opt.apply_gradients(zip(grads, base_model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataset, n_epochs=10, max_steps_per_epoch=None, adversarial=False):\n",
    "    for epoch in range(n_epochs):\n",
    "        for i, batch in enumerate(train_dataset):\n",
    "            xs, ys = batch\n",
    "            if max_steps_per_epoch is not None:\n",
    "                if i == max_steps_per_epoch:\n",
    "                    break\n",
    "#             adversarial = (epoch >= 1)\n",
    "            l1, l2 = train_step(xs['fla'], ys['lbl'][:, 0, 0, 0])\n",
    "#             del batch\n",
    "            clear_output(wait=True)\n",
    "            print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))\n",
    "            print(f'Step {i+1}')\n",
    "            print(f'Generator Loss: {round(l1.numpy(), 2)}')\n",
    "            if adversarial:\n",
    "                print(f'Discriminator Loss: {round(l2.numpy(), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
