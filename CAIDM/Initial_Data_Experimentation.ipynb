{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 15 11:52:01 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:3B:00.0 Off |                  N/A |\n",
      "| 23%   24C    P8    15W / 250W |  10912MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:5E:00.0 Off |                  N/A |\n",
      "| 23%   24C    P8     8W / 250W |  10914MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 108...  Off  | 00000000:AF:00.0 Off |                  N/A |\n",
      "| 23%   27C    P8     8W / 250W |  10914MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  Off  | 00000000:D8:00.0 Off |                  N/A |\n",
      "| 23%   25C    P8     8W / 250W |  10914MiB / 11178MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2022-06-15 11:52:01 ] CUDA_VISIBLE_DEVICES already manually set to: 0        \n"
     ]
    }
   ],
   "source": [
    "from jarvis.utils.general import gpus\n",
    "\n",
    "gpus.autoselect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from jarvis.train import datasets\n",
    "from jarvis.utils.display import imshow\n",
    "from tensorflow.keras import Input\n",
    "from jarvis.train.client import Client\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mri(mri):\n",
    "    for i in range(mri.shape[0]):\n",
    "        clear_output(wait=True)\n",
    "        plt.axis(False)\n",
    "        plt.imshow(mri[i, :, :, 0], cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- prepare generators\n",
    "client = Client('/data/raw/miccai_rsna/data/ymls/client-3d.yml')\n",
    "gen_train, gen_valid = client.create_generators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0]]]]\n"
     ]
    }
   ],
   "source": [
    "# --- Show a sample training set\n",
    "xs, ys = next(gen_train)\n",
    "# imshow(xs['t2w'][0][24], radius=1)\n",
    "print(ys['lbl'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 48, 96, 96, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flair = xs['fla']\n",
    "flair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair1 = flair[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 96, 96, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flair1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8152425315355885"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(flair1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAACy0lEQVR4nO3YMQoDMQwAwdOR/39Z+YBJF7zFTCk3ahaBZ3cfoOe9vQBwJk6IEidEiROixAlRn1+PM+MrF/5sd+c0dzkhSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghanb39g7AgcsJUeKEKHFClDghSpwQJU6I+gI34gvJPjrjHQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_mri(flair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lbl': array([[[[[0]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[0]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[0]]]],\n",
       " \n",
       " \n",
       " \n",
       "        [[[[1]]]]], dtype=uint8)}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys['lbl'][:, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['t2w', 't1w', 't1wce', 'fla', 'lbl'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xs key: t2w      | shape = (4, 48, 96, 96, 1)\n",
      "xs key: t1w      | shape = (4, 48, 96, 96, 1)\n",
      "xs key: t1wce    | shape = (4, 48, 96, 96, 1)\n",
      "xs key: fla      | shape = (4, 48, 96, 96, 1)\n",
      "xs key: lbl      | shape = (4, 1, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# --- Print keys \n",
    "for key, arr in xs.items():\n",
    "    print('xs key: {} | shape = {}'.format(key.ljust(8), arr.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create model inputs\n",
    "inputs = client.get_inputs(Input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t2w': <KerasTensor: shape=(None, 48, 96, 96, 1) dtype=float32 (created by layer 't2w')>,\n",
       " 't1w': <KerasTensor: shape=(None, 48, 96, 96, 1) dtype=float32 (created by layer 't1w')>,\n",
       " 't1wce': <KerasTensor: shape=(None, 48, 96, 96, 1) dtype=float32 (created by layer 't1wce')>,\n",
       " 'fla': <KerasTensor: shape=(None, 48, 96, 96, 1) dtype=float32 (created by layer 'fla')>,\n",
       " 'lbl': <KerasTensor: shape=(None, 1, 1, 1, 1) dtype=uint8 (created by layer 'lbl')>}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv3D, GlobalAveragePooling3D, Flatten, InputLayer, MaxPool3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.Sequential()\n",
    "base_model.add(InputLayer(input_shape=(48, 96, 96, 1)))\n",
    "base_model.add(Conv3D(16, 3, activation='relu', padding='same', data_format='channels_first'))\n",
    "base_model.add(MaxPool3D(padding='same', data_format='channels_first'))\n",
    "base_model.add(Conv3D(32, 3, activation='relu', padding='same', data_format='channels_first'))\n",
    "base_model.add(MaxPool3D(padding='same', data_format='channels_first'))\n",
    "base_model.add(Conv3D(48, 3, activation='relu', padding='same', data_format='channels_first'))\n",
    "base_model.add(MaxPool3D(padding='same', data_format='channels_first'))\n",
    "# base_model.add(Conv3D(64, 3, activation='relu', padding='same', data_format='channels_first'))\n",
    "# base_model.add(MaxPool3D(padding='same', data_format='channels_first'))\n",
    "# base_model.add(Conv3D(80, 3, activation='relu', padding='same', data_format='channels_first'))\n",
    "# base_model.add(MaxPool3D(padding='same', data_format='channels_first'))\n",
    "\n",
    "base_model.add(Flatten())\n",
    "base_model.add(Dense(128, activation='relu'))\n",
    "base_model.add(Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_23 (Conv3D)           (None, 16, 96, 96, 1)     20752     \n",
      "_________________________________________________________________\n",
      "conv3d_24 (Conv3D)           (None, 32, 96, 96, 1)     13856     \n",
      "_________________________________________________________________\n",
      "conv3d_25 (Conv3D)           (None, 48, 96, 96, 1)     41520     \n",
      "_________________________________________________________________\n",
      "conv3d_26 (Conv3D)           (None, 64, 96, 96, 1)     83008     \n",
      "_________________________________________________________________\n",
      "conv3d_27 (Conv3D)           (None, 80, 96, 96, 1)     138320    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 737280)            0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128)               94371968  \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 94,669,553\n",
      "Trainable params: 94,669,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "bce = BinaryCrossentropy()\n",
    "# @tf.function\n",
    "def train_step(x, y):\n",
    "#     print(y.shape)\n",
    "    with tf.GradientTape() as tape:\n",
    "#         print('beginning training...')\n",
    "        y_hat = base_model(x, training=True)\n",
    "#         print(y_hat.shape)\n",
    "#         print('done training...')\n",
    "        loss = bce(y, y_hat)\n",
    "    grads = tape.gradient(loss, base_model.trainable_variables)\n",
    "    opt.apply_gradients(zip(grads, base_model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "annoying_case = None\n",
    "annoying_case_unproc = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataset, n_epochs=1, max_steps_per_epoch=None):\n",
    "    global annoying_case, annoying_case_unproc\n",
    "    for epoch in range(n_epochs):\n",
    "        for i, batch in enumerate(train_dataset):\n",
    "            xs, ys = batch\n",
    "            print(xs['fla'].shape)\n",
    "            fla = xs['fla']\n",
    "            x_prep = fla # (fla-np.min(fla))/(np.max(fla)-np.min(fla))\n",
    "            if max_steps_per_epoch is not None:\n",
    "                if i == max_steps_per_epoch:\n",
    "                    break\n",
    "#             adversarial = (epoch >= 1)\n",
    "            if(np.isnan(x_prep).any()):\n",
    "                continue\n",
    "            l1 = train_step(x_prep, ys['lbl'].reshape(4, 1))#[:, 0, 0, 0])\n",
    "#             del batch\n",
    "            clear_output(wait=True)\n",
    "            if np.isnan(np.max(x_prep)) or np.isnan(np.min(x_prep)):\n",
    "                annoying_case = x_prep\n",
    "                annoying_case_unproc = fla\n",
    "#             show_mri(x_prep[0])\n",
    "            print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))\n",
    "            print(f'Step {i+1}')\n",
    "#             print(f'MRI Shape: {x_prep.shape}')\n",
    "#             print(f'Max Flair: {np.max(x_prep)}')\n",
    "#             print(f'Min Flair: {np.min(x_prep)}')\n",
    "            print(f'Loss: {round(l1.numpy(), 2)}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "Step 100\n",
      "Loss: 0.6700000166893005\n",
      "(4, 48, 96, 96, 1)\n"
     ]
    }
   ],
   "source": [
    "# --- prepare generators\n",
    "client = Client('/data/raw/miccai_rsna/data/ymls/client-3d.yml')\n",
    "gen_train, gen_valid = client.create_generators()\n",
    "train(gen_train, max_steps_per_epoch=100, n_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_VAL_SCANS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "labels = []\n",
    "for i, batch in enumerate(gen_valid):\n",
    "    xs, ys = batch\n",
    "    pred = base_model.predict(xs['fla'])\n",
    "    y = ys['lbl']\n",
    "    labels.append(y.reshape(4, 1))\n",
    "    preds.append(pred)\n",
    "    if i == NUM_VAL_SCANS:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.array(preds).reshape(-1,)\n",
    "labels = np.array(labels).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956, 0.52749956,\n",
       "       0.52749956, 0.52749956, 0.52749956, 0.52749956], dtype=float32)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[preds > 0.5] = 1\n",
    "preds[preds <= 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated on 100 scans...\n",
      "Accuracy: 0.4900990099009901\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(preds, labels)\n",
    "print(f'Validated on {NUM_VAL_SCANS} scans...')\n",
    "print(f'Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
